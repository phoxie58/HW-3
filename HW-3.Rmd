---
title: "MATH 216 Homework 3"
author: "Phil Hoxie"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(Quandl))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(scales))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(plotly))
```


## Admistrative:

Please indicate

* Who you collaborated with:I pulled a bit of code from the HW-2 markdown file (the code on jobs)
* Roughly how much time you spent on this HW: 11
* What gave you the most trouble:The dates for the Jukebox set and using the predict function 
* Any comments you have: 3 missing observations accounted for most of my wasted time on this assignment. It should have been more like 7 hours rather than 11. 


## Data

* You must first copy the file `profiles.csv` from `HW-2` to the `data` folder
in the `HW-3` directory
* We also consider all 222,540 songs played in the Reed College pool hall
jukebox from Nov 30, 2003 to Jan 22, 2009 (included in `HW-3` folder). 

```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
profiles <- read.csv("data/profiles.csv", header=TRUE) %>% 
  tbl_df()
profiles <- na.omit(profiles)
jukebox <- read.csv("data/jukebox.csv", header=TRUE) %>% 
  tbl_df()

```





## Question 1:

For this question we will be picking up from where we left off in HW-2,
specifically the OkCupid dataset.


### a)

Using your exploratory data analysis from HW-2, fit a logistic regression to
predict individual's gender and interpret your results.

```{r, echo=FALSE, fig.width=12, results='hide', fig.height=6}
profiles <-  profiles %>% mutate(income = replace(income, income<0, NA))

profiles <- profiles %>% 
  mutate(female = ifelse(sex=="f", 1, 0))

profiles <- profiles %>% 
  mutate(athletic = ifelse(body_type=="athletic", 1, 0))

profiles <- profiles %>% 
  mutate(curvy = ifelse(body_type=="curvy", 1, 0))

profiles <- profiles %>% 
  mutate(rep.inc = ifelse(is.na(income), 0, 1))

find_query <- function(char.vector, query){
  which.has.query <- grep(query, char.vector, ignore.case = TRUE)
  length(which.has.query) != 0
}
profile_has_word <- function(data.frame, query){
  query <- tolower(query)
  has.query <- apply(data.frame, 1, find_query, query=query)
  return(has.query)
}

# Search for the string "wine"
profiles$has.wine <- profile_has_word(data.frame = profiles, query = "wine")
x <- table(profiles$has.wine)
x

profiles <- profiles %>% 
  mutate(has.wine = ifelse(has.wine == TRUE, 1, 0))

profiles <-  profiles %>% mutate(income = replace(income, income<0, NA))

profiles$is.smoker <- profiles$smokes
levels(profiles$is.smoker) <- c("NA", "no", "yes", "yes", "yes", "yes")
count(profiles, is.smoker)

profiles <- profiles %>% 
  mutate(is.smoker = ifelse(is.smoker == "yes", 1, 0))

profiles <- profiles %>% 
  mutate(is.admin = ifelse(job == "clerical / administrative", 1, 0))

profiles <- profiles %>% 
  mutate(is.med = ifelse(job == "medicine / health", 1, 0))

profiles <- profiles %>% 
  mutate(is.ed = ifelse(job == "education / academia", 1, 0))

profiles <- profiles %>% 
  mutate(is.tech = ifelse(job == "computer / hardware / software", 1, 0))

profiles <- profiles %>% 
  mutate(is.construction = ifelse(job == "construction / craftsmanship", 1, 0))

```

```{r, echo=FALSE, fig.width=12, fig.height=6}
model.all <- glm(female ~ height + has.wine + is.smoker + athletic + rep.inc + is.admin + is.med + is.ed + is.tech + is.construction, data=profiles, family=binomial)
kable(summary(model.all)$coef, digits=2)
all <- coefficients(model.all)
coef <- (1/(1+exp(-all))) %>% round(3)
data.frame(coef) %>% kable()

```



### b)

Plot a histogram of the fitted probabilities $\widehat{p}_i$ for all users $i=1,
\ldots, n=59946$ in your dataset.

```{r, echo=FALSE, fig.width=12, fig.height=6}
profiles <- profiles %>% mutate(p.hat = fitted(model.all))
threshold <- 0.5
fit <- qplot(fitted(model.all)) + xlab("Fitted p.hat")+
  ggtitle("Fitted Values Histogram")+ 
  geom_vline(xintercept=threshold, col="red", size=1)
fit
```


### c)

Use a *decision threshold* of $p^*=0.5$ to make an explicit prediction for each
user $i$'s sex and save this in a variable `predicted_sex`. In other words, for user $i$

* If $\widehat{p}_i > p^*$, set `predicted_sex = 1` i.e. they are female
* If $\widehat{p}_i < p^*$, set `predicted_sex = 0` i.e. they are male

Display a 2 x 2 contigency table of `sex` and `predicted_sex` i.e. compare the 
predicted sex to the actual sex of all users. The sum of all the elements in
your table should be $n=59946$. Comment on how well our predictions fared.

```{r, echo=FALSE, fig.width=12, fig.height=6}
profiles <- profiles %>% mutate(predict.female = ifelse(p.hat>=.5, 1, 0))

predictions <- profiles %>% 
  group_by(predict.female, female) %>% 
  tally()
kable(predictions)
```

Of the 59,943 Okcupid users, 50,867 were correctly identified as male or female using my model. That is a success rate of about 85%, which is fairly good. 

### d)

Say we wanted to have a **false positive rate** of about 20%, i.e. of the people
we predicted to be female, we want to be wrong no more than 20% of the time. What
decision threshold $p^*$ should we use?

```{r, echo=FALSE, fig.width=12, fig.height=6}

```





## Question 2:

Using the jukebox data, plot a time series of the number of songs played each
week over the entire time period. i.e.

* On the x-axis present actual dates (not something like Week 93, which doesn't 
mean anything to most people).
* On the y-axis present the total number of songs.

What seasonal (i.e. cyclical) patterns do you observe?

```{r, echo=FALSE, results='hide', fig.width=12, fig.height=6}

jukebox <- jukebox %>% 
  mutate(date = parse_date_time(date_time, "%b %d %H%M%S %y" )) 

jukebox <- jukebox %>% 
  mutate(month = month(date), day = day(date), year = year(date)) 

jukebox <- jukebox %>% 
  unite(md, month, day, sep = ".")

songs.by.date <- jukebox %>% 
  group_by(md) %>% 
  tally() 
```

```{r, echo=FALSE, fig.width=12, fig.height=6}
p <- ggplot(songs.by.date, aes(x=as.Date(md, "%m.%d"), y=n)) + 
  geom_point() + 
  scale_x_date(breaks=date_breaks("month"), labels=date_format("%m"))+
  xlab("Months")+
  ylab("Number of Songs Played")+
  ggtitle("Total Songs Played by Date 2003-2009")
p
```

There is a clear drop off in songs played during the summer. This makes sense becase school is not in session and there are fewer people on campus. 

```{r, echo=FALSE, fig.width=12, fig.height=6}
jukebox <- jukebox %>% 
  unite(mdy, md, year, sep = ".")

songs.over.time <- jukebox %>% 
  group_by(mdy) %>% 
  tally() 
songs.over.time <- songs.over.time %>% 
  mutate(date = mdy(mdy))


time.plot <- ggplot(songs.over.time, aes(x=date, y=n)) + 
  geom_point() +
  geom_smooth(n=30)+
  xlab("Date")+
  ylab("Number of Songs Played")+
  ggtitle("Total Songs Played each Day 2003-2009")
time.plot
```

When you look at the data over the entire time period, and add a smoother, it is clear that the cyclical trend follows the school year. More songs are played durind the semester, and drop offs can be seen over winter and summer breaks. 

## Question 3:

Using the jukebox data, what are the top 10 artists played during the "graveyard
shift" during the academic year? Define

* the "graveyard shift" as midnight to 8am
* the academic year as September through May (inclusive)

```{r, echo=FALSE, fig.width=12, fig.height=6}
jukebox <- jukebox %>% 
  mutate(hr = hour(date), min = minute(date), sec = second(date), month = month(date))

jukebox <- jukebox %>% 
  mutate(graveyard = ifelse(month>=9 & hr>=0 & hr<=8,1, ifelse(month<=5 & hr>=0 & hr<=8, 1,0)))

grave.yard <- jukebox %>% 
  group_by(month, graveyard) %>% 
  tally()

grave.yard.artists <- jukebox %>% 
  filter(graveyard == 1) %>% 
  group_by(artist) %>% 
  tally() %>% 
  arrange(desc(n)) %>% 
  slice(1:10)
kable(grave.yard.artists)
```

Not all is lost when it comes to Reed students, because some of them seem to have decent taste in late night hangout music. Outkast is a poor choice, which was the most played. However, the Beatles, Led Zeplin, the Stones, and the Chili Peppers are good picks no matter what time of night. 


## Question 4:

We want to compare the volatility of 

* bitcoin prices
* gold prices

Let our measure of volatility be the relative change from day-to-day in price. 
Let the reference currency be US dollars. Analyze these results and provide
insight to a foreign currency exchanger.

```{r, echo=FALSE, fig.width=12, fig.height=6}
bitcoin <- Quandl("COINBASE/USD") %>% 
  tbl_df() %>% 
  rename(bitcoin.usd = High)
gold <- Quandl("BUNDESBANK/BBK01_WT5511") %>% 
  tbl_df() %>% 
  rename(gold.usd = Value)

prices <- left_join(bitcoin, gold, by = "Date") %>% 
  select(Date, bitcoin.usd, gold.usd) 

prices <- prices %>% 
  mutate(bit.perc.chng = ((bitcoin.usd - lag(bitcoin.usd))/(lag(bitcoin.usd))))

prices <- prices %>% 
  mutate(gold.perc.chng = ((gold.usd - lag(gold.usd))/(lag(gold.usd))))

bg <- ggplot(data = prices, aes(x = gold.perc.chng, y = bit.perc.chng))+
  geom_point()+
  ggtitle("Comparison of Percent Change in Price of Bitcoin and Gold")+
  xlab("Daily Percent Change in Gold Price (USD)")+
  ylab("Daily Percent Change in Bitcoin Price (USD)")
bg

reg <- lm(data = prices, gold.perc.chng ~ bit.perc.chng)
kable(summary(reg)$coef, digits=2)
```

Note: Gold had missing observations that were dropped for the sake of comparison.

The p-value for the regression is insignificant, therefore we cannot reject the null hypothesis that there is no correlation between the percentage change in bitcoin and gold prices. 

```{r, echo=FALSE, fig.width=12, fig.height=6}
prices.na.rm <- prices %>% 
  na.omit()

bg.time <- ggplot(data = prices.na.rm, aes(x = Date)) + 
  geom_line(aes(y = gold.usd), col = "red") + 
  geom_line(aes(y = bitcoin.usd), col = "blue")+
  xlab("Date")+
  ylab("Price (USD)")+
  ggtitle("Price (USD) of Gold and Bitcoin Over Time")
ggplotly(bg.time)
```

It looks like there might be an ever so slight negative correlation between the change in prices. However, the previous regression and plot show no such relationship at a statistically significant level.

```{r, echo=FALSE, fig.width=12, fig.height=6}
bg.time.perc <- ggplot(data = prices.na.rm, aes(x = Date))+
  geom_line(aes(y = gold.perc.chng), col = "red") + 
  geom_line(aes(y = bit.perc.chng), col = "blue")+
  ggtitle("Percent Change in Price of Bitcoin and Gold Over Time")+
  xlab("Date")+
  ylab("Percent Change in Price (USD)")
ggplotly(bg.time.perc)
```
The trading advice that I would give is to trade bitcoin because it is much more volitile which could lead to short-term profits if timed correctly. Gold, on the other hand is much more expensive and it's percentage change in price curve seems to be a lot less volitile.  

## Question 5:

Using the data loaded from Quandl below, plot a time series using `geom_line()`
comparing cheese and milk production in the US from 1930 to today. Comment on this.

* Cheese [page](https://www.quandl.com/data/USDANASS/NASS_CHEESEPRODUCTIONMEASUREDINLB-Cheese-Production-Measured-In-Lb)
* Milk [page](https://www.quandl.com/data/USDANASS/NASS_MILKPRODUCTIONMEASUREDINLB-Milk-Production-Measured-In-Lb)

```{r, echo=FALSE, results = "hide", fig.width=12, fig.height=6}
cheese <- Quandl("USDANASS/NASS_CHEESEPRODUCTIONMEASUREDINLB") %>% 
  tbl_df()
milk <-  Quandl("USDANASS/NASS_MILKPRODUCTIONMEASUREDINLB") %>% 
  tbl_df()

dairy <- left_join(cheese, milk, by = "Date") %>% 
  mutate(cheese.price = Value.x, milk.price = Value.y, date = Date) %>% 
  select(date, cheese.price, milk.price)

dairy.long <- dairy %>% 
  rename(cheese = cheese.price, milk = milk.price) %>% 
  gather(key = product, price, cheese:milk) %>% 
  na.omit()
```

```{r, echo=FALSE, fig.width=12, fig.height=6}
mc <- ggplot(data = dairy.long, aes(x=date, y = price, color = product))+
  geom_line()+
  ylab("Price (USD)")+
  ggtitle("Milk and Cheese Prices over Time")
ggplotly(mc)
```

Milk and Cheese prices are of completely different magnitudes, so in order to show what is really going on, it is necessary to index the prices. Indexing uses a reference year to show the relative change. The formula is Pindex = (Pt/Pref)*100. I chose to use 1940 as the index reference year, so both the milk and cheese price indexes are equal to 100 in 1940. 

```{r, echo=FALSE, fig.width=12, fig.height=6}
dairy.index <- dairy %>% 
  mutate(milk = (milk.price/1.09412e+11)*100, 
         cheese = (cheese.price/785490000)*100) %>% 
  gather(key = product, price.index.1940, cheese:milk) %>% 
  na.omit()

mc.index <- ggplot(data = dairy.index, aes(x=date, y = price.index.1940, color = product))+
  geom_line()+
  ylab("Indexed Prices (USD, 1940)")+
  ggtitle("Milk and Cheese Indexed Prices over Time")
ggplotly(mc.index)
```

This chart shows that milk prices have actually remained fairly stable over time relative to the massive increase in cheese prices. 
